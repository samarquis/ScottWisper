---
phase: 01-core-technology-validation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified: [WhisperService.cs, AudioCaptureService.cs, ScottWisper.csproj]
autonomous: true
user_setup:
  - service: openai
    why: "Speech-to-text conversion using Whisper API"
    env_vars:
      - name: OPENAI_API_KEY
        source: "OpenAI Dashboard -> API Keys"
    dashboard_config:
      - task: "Generate API key"
        location: "OpenAI Dashboard -> API Keys -> Create new secret key"
must_haves:
  truths:
    - "Audio capture can record microphone input in real-time"
    - "OpenAI Whisper API returns accurate transcription of clear speech"
    - "API calls stay within free tier rate limits"
  artifacts:
    - path: "WhisperService.cs"
      provides: "OpenAI Whisper API integration"
      contains: "OpenAI"
      exports: ["TranscribeAudioAsync"]
    - path: "AudioCaptureService.cs"
      provides: "Real-time microphone audio capture"
      contains: "MediaFoundation"
      exports: ["StartCapture", "StopCapture"]
  key_links:
    - from: "AudioCaptureService.cs"
      to: "WhisperService.cs"
      via: "audio stream API call"
      pattern: "TranscribeAudioAsync"
    - from: "WhisperService.cs"
      to: "OpenAI API"
      via: "HTTP client"
      pattern: "api\\.openai\\.com"
---

<objective>
Integrate real-time speech-to-text conversion using OpenAI Whisper API with Windows audio capture.

Purpose: Enable accurate transcription of user speech by capturing microphone audio and converting it to text using OpenAI's Whisper API, establishing the core dictation functionality.
Output: Working audio capture service with Whisper API integration that can transcribe speech in real-time.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
</context>

<tasks>

<task type="auto">
  <name>Setup project dependencies for audio and API integration</name>
  <files>ScottWisper.csproj</files>
  <action>
Add required NuGet packages for audio capture and HTTP communication:
1. Add Microsoft.Windows.SDK.Contracts for Windows API access
2. Add System.Net.Http for HTTP client functionality
3. Add Newtonsoft.Json for JSON serialization of API responses
4. Add NAudio.Audio for cross-platform audio capture (backup option)
5. Configure package versions compatible with .NET 8 and WinUI 3
6. Ensure packages are restored successfully
7. Add necessary using statements and namespace references

Package versions to use:
- Microsoft.Windows.SDK.Contracts: 10.0.22621.2428
- Newtonsoft.Json: 13.0.3
- NAudio: 2.2.1
</action>
  <verify>dotnet restore completes successfully and packages are installed</verify>
  <done>All required dependencies are installed and project builds without errors</done>
</task>

<task type="auto">
  <name>Implement audio capture service for real-time microphone input</name>
  <files>AudioCaptureService.cs</files>
  <action>
Create AudioCaptureService.cs for real-time microphone recording:
1. Use Windows Media Foundation APIs via WinRT for low-latency audio capture
2. Implement audio capture at 16kHz sample rate, mono channel (Whisper optimal)
3. Create audio buffer management for streaming chunks to API
4. Add automatic audio device detection and selection
5. Implement start/stop capture methods with proper resource management
6. Add error handling for microphone permissions and device availability
7. Include audio level monitoring for voice activity detection
8. Ensure audio format compatibility with Whisper API requirements

Technical specifications:
- Sample rate: 16000 Hz
- Channels: 1 (mono)
- Bit depth: 16-bit
- Audio format: PCM WAV compatible
- Buffer size: 1024 samples for low latency
- Use WASAPI (Windows Audio Session API) for capture
</action>
  <verify>Audio capture starts successfully and produces valid audio data</verify>
  <done>Real-time microphone audio capture works with proper format and quality</done>
</task>

<task type="auto">
  <name>Integrate OpenAI Whisper API for speech-to-text conversion</name>
  <files>WhisperService.cs</files>
  <action>
Create WhisperService.cs for OpenAI Whisper API integration:
1. Implement HTTP client for OpenAI API communication
2. Add Whisper API endpoint configuration (api.openai.com/v1/audio/transcriptions)
3. Create audio file upload functionality in proper format (WAV/MP3)
4. Implement async transcription method with proper error handling
5. Add API key management through environment variables
6. Include retry logic for network failures and rate limiting
7. Add response parsing and text extraction from API results
8. Implement cost tracking for API usage monitoring
9. Add support for real-time streaming (if supported by API)

API configuration:
- Model: whisper-1
- Language: en (English)
- Response format: json
- Temperature: 0.0 for consistent results
- Use environment variable OPENAI_API_KEY for authentication
</action>
  <verify>Whisper API calls return accurate transcriptions for test audio files</verify>
  <done>OpenAI Whisper API integration works with accurate speech-to-text conversion</done>
</task>

</tasks>

<verification>
1. All required NuGet packages are installed and project builds successfully
2. AudioCaptureService can start/stop microphone recording without errors
3. WhisperService can authenticate with OpenAI API using environment variable
4. Audio captured from microphone can be successfully transcribed by Whisper API
5. Transcription accuracy meets minimum requirements for clear English speech
6. Error handling works for microphone permissions and API failures
7. API usage tracking captures request count and estimated costs
</verification>

<success_criteria>
- Real-time audio capture from microphone works reliably
- OpenAI Whisper API integration authenticates and transcribes accurately
- Audio format matches Whisper API requirements (16kHz, mono, PCM)
- Error handling covers common failure scenarios
- Basic usage tracking is implemented for cost monitoring
- End-to-end audio capture to text conversion pipeline functions
</success_criteria>

<output>
After completion, create `.planning/phases/01-core-technology-validation/01-02-SUMMARY.md`
</output>